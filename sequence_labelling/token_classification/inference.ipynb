{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd3d3640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AlbertForTokenClassification, AlbertTokenizer\n",
    "import numpy as np\n",
    "import inference_params\n",
    "import json\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f7962d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_path = inference_params.LABEL_ENCODER_PATH\n",
    "tag_values = ['none ', 'none', 'exclamation', 'comma', 'viram', 'PAD']\n",
    "with open(label_encoder_path) as label_encoder:\n",
    "    train_encoder = json.load(label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b7f72b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AlbertTokenizer.from_pretrained('ai4bharat/indic-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17880f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     2, 171759,    516,  27926,     37,  59251, 126136,   1825,     31,\n",
       "           3557,  17137,    555,  41281,    130, 175206,   7571,  71080,     10,\n",
       "             66,   1301,  90529,   9327,   4765,  73061,  11867, 125491,   1342,\n",
       "             29,     45,  13015,  52974,   2266,     37,  17132,   1551,     16,\n",
       "              3]], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = \"विकिपीडिया सभी विषयों पर प्रामाणिक और उपयोग परिवर्तन व पुनर्वितरण के लिए स्वतन्त्र ज्ञानकोश बनाने का एक बहुभाषीय प्रकल्प है\"\n",
    "#test_sentence = \"अमेरिका समेत अन्य देशों से जो मदद भारत पहुंची उसका क्या हुआ\"\n",
    "tokenized_sentence = tokenizer.encode(test_sentence)\n",
    "input_ids = torch.tensor([tokenized_sentence]).cuda()\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27cb3d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertForTokenClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias', 'sop_classifier.classifier.weight', 'sop_classifier.classifier.bias']\n",
      "- This IS expected if you are initializing AlbertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AlbertForTokenClassification.from_pretrained('ai4bharat/indic-bert',\n",
    "                                                     num_labels=len(train_encoder),\n",
    "                                                     output_attentions=False,\n",
    "                                                     output_hidden_states=False)\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    print(\"Using \", torch.cuda.device_count(), \"GPUs\")\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d7b7de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(inference_params.CHECKPOINT_PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb123e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): AlbertForTokenClassification(\n",
       "    (albert): AlbertModel(\n",
       "      (embeddings): AlbertEmbeddings(\n",
       "        (word_embeddings): Embedding(200000, 128, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 128)\n",
       "        (token_type_embeddings): Embedding(2, 128)\n",
       "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (encoder): AlbertTransformer(\n",
       "        (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "        (albert_layer_groups): ModuleList(\n",
       "          (0): AlbertLayerGroup(\n",
       "            (albert_layers): ModuleList(\n",
       "              (0): AlbertLayer(\n",
       "                (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (attention): AlbertAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                  (output_dropout): Dropout(p=0, inplace=False)\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                )\n",
       "                (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c394f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input_ids)\n",
    "label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a88a2bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cc6a061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hyp': 0, 'qm': 1, 'comma': 2, 'end': 3, 'blank': 4, 'ex': 5, 'PAD': 6}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "990a3ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '▁विकिपीडिया',\n",
       " '▁सभी',\n",
       " '▁विषयों',\n",
       " '▁पर',\n",
       " '▁परा',\n",
       " 'माण',\n",
       " 'िक',\n",
       " '▁और',\n",
       " '▁उपयोग',\n",
       " '▁परि',\n",
       " 'वर',\n",
       " 'तन',\n",
       " '▁व',\n",
       " '▁पुनर',\n",
       " 'वि',\n",
       " 'तरण',\n",
       " '▁के',\n",
       " '▁लिए',\n",
       " '▁स',\n",
       " 'वतन',\n",
       " 'तर',\n",
       " '▁ज',\n",
       " 'ञ',\n",
       " 'ान',\n",
       " 'कोश',\n",
       " '▁बनाने',\n",
       " '▁का',\n",
       " '▁एक',\n",
       " '▁बहु',\n",
       " 'भाष',\n",
       " 'ीय',\n",
       " '▁पर',\n",
       " 'कल',\n",
       " 'प',\n",
       " '▁है',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82744e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))\n",
    "print(len(label_indices[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29734eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokens, new_labels = [], []\n",
    "for token, label_idx in zip(tokens, label_indices[0]):\n",
    "    if token.startswith(\"▁\"):\n",
    "        new_tokens[-1] = new_tokens[-1] + token[1:]\n",
    "    else:\n",
    "        new_labels.append(list(train_encoder.keys())[list(train_encoder.values()).index(label_idx)])\n",
    "        new_tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19967397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blank\t[CLS]विकिपीडियासभीविषयोंपरपरा\n",
      "blank\tमाण\n",
      "blank\tिकऔरउपयोगपरि\n",
      "blank\tवर\n",
      "blank\tतनवपुनर\n",
      "blank\tवि\n",
      "blank\tतरणकेलिएस\n",
      "blank\tवतन\n",
      "blank\tतरज\n",
      "blank\tञ\n",
      "blank\tान\n",
      "blank\tकोशबनानेकाएकबहु\n",
      "blank\tभाष\n",
      "blank\tीयपर\n",
      "blank\tकल\n",
      "blank\tपहै\n",
      "blank\t[SEP]\n"
     ]
    }
   ],
   "source": [
    "for token, label in zip(new_tokens, new_labels):\n",
    "    print(\"{}\\t{}\".format(label, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21cf4a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['विकिपीडिया', 'सभी', 'विषयों', 'पर', 'परामाणिक', 'और', 'उपयोग', 'परिवरतन', 'व', 'पुनरवितरण', 'के', 'लिए', 'सवतनतर', 'जञानकोश', 'बनाने', 'का', 'एक', 'बहुभाषीय', 'परकलप', 'है']\n",
      "['blank', 'blank', 'blank', 'blank', 'blank', 'blank', 'blank', 'blank', 'blank', 'blank', 'blank', 'blank', 'blank', 'blank', 'blank', 'blank', 'blank', 'blank', 'blank', 'end']\n"
     ]
    }
   ],
   "source": [
    "new_tokens = []\n",
    "new_labels = []\n",
    "for i in range(1, len(tokens)-1):\n",
    "    if tokens[i].startswith(\"▁\"):\n",
    "        current_word = tokens[i][1:]\n",
    "        new_labels.append(list(train_encoder.keys())[list(train_encoder.values()).index(label_indices[0][i])])\n",
    "        for j in range(i+1, len(tokens)-1):\n",
    "            if not tokens[j].startswith(\"▁\"):\n",
    "                current_word = current_word + tokens[j]\n",
    "            if tokens[j].startswith(\"▁\"):\n",
    "                break\n",
    "        new_tokens.append(current_word)\n",
    "print(new_tokens)\n",
    "print(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f36b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = test_sentence.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ecb9338",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sentence)==len(new_tokens)==len(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89b10adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(sentence))\n",
    "print(len(new_tokens))\n",
    "print(len(new_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b47b2513",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_dict = {'hyp': '-', 'qm': '? ', 'comma': ', ', 'end': '। ', 'blank': ' ', 'ex': '! '}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce3d9e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'विकिपीडिया सभी विषयों पर प्रामाणिक और उपयोग परिवर्तन व पुनर्वितरण के लिए स्वतन्त्र ज्ञानकोश बनाने का एक बहुभाषीय प्रकल्प है। '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ''\n",
    "for word, punctuation in zip(sentence, new_labels):\n",
    "    s = s + word + punctuation_dict[punctuation]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adebe1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
